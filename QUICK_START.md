# Quick Start Guide

## Installation

```bash
cd /workspaces/mkdocs-material/mkdocs-ai-assistant
pip install -e .
```

## Test the Plugin

```bash
cd tests/test_site
mkdocs build
```

**Expected Output**:
```
INFO - Cache initialized at .ai-cache
ERROR - Failed to initialize AI provider: API key required
WARNING - AI features will be disabled
INFO - Documentation built in 0.19 seconds
```

This is correct! The plugin works, it just needs an API key.

## Add API Key

```bash
export OPENROUTER_API_KEY="your-key-here"
# or
export GEMINI_API_KEY="your-key-here"
```

## Use in Your Project

Add to your `mkdocs.yml`:

```yaml
plugins:
  - search
  - ai-assistant:
      provider:
        name: openrouter  # or gemini, anthropic, ollama
        api_key: !ENV OPENROUTER_API_KEY
        model: anthropic/claude-3.5-sonnet
      
      cache:
        enabled: true
        dir: .ai-cache
      
      generation:
        enabled: true
```

## What Works Now

âœ… Plugin installation  
âœ… Configuration loading  
âœ… Provider initialization  
âœ… Caching system  
âœ… MkDocs integration  
âœ… Graceful error handling  

## What's Coming Next

ðŸš§ Document generation (Priority 1)  
ðŸš§ Content enhancement (Priority 2)  
ðŸš§ Semantic search (Priority 3)  
ðŸš§ Asset processing (Priority 4)  
ðŸš§ Obelisk integration (Priority 5)  

## File Structure

```
mkdocs-ai-assistant/
â”œâ”€â”€ mkdocs_ai/              # Main package
â”‚   â”œâ”€â”€ plugin.py          # Main plugin
â”‚   â”œâ”€â”€ config.py          # Configuration
â”‚   â”œâ”€â”€ providers/         # AI providers (4 implemented)
â”‚   â””â”€â”€ cache/             # Caching system
â”‚
â”œâ”€â”€ tests/test_site/       # Test site
â”‚   â”œâ”€â”€ mkdocs.yml        # Example config
â”‚   â””â”€â”€ docs/             # Documentation
â”‚
â”œâ”€â”€ README.md              # Full documentation
â”œâ”€â”€ IMPLEMENTATION_STATUS.md  # Detailed status
â”œâ”€â”€ SESSION_SUMMARY.md     # What we built
â””â”€â”€ QUICK_START.md         # This file
```

## Key Files to Read

1. **README.md** - Complete overview
2. **IMPLEMENTATION_STATUS.md** - Current status
3. **SESSION_SUMMARY.md** - Session recap
4. **mkdocs_ai/plugin.py** - Main code
5. **tests/test_site/mkdocs.yml** - Config example

## Supported Providers

| Provider | Status | Use Case |
|----------|--------|----------|
| OpenRouter | âœ… Ready | Production (recommended) |
| Gemini | âœ… Ready | Testing/development |
| Anthropic | âœ… Ready | Direct Claude access |
| Ollama | âœ… Ready | Local LLM (future) |

## Configuration Options

See `mkdocs_ai/config.py` for all options.

Key settings:
- `provider.name` - Which AI service to use
- `provider.model` - Which model to use
- `cache.enabled` - Enable caching (recommended)
- `generation.enabled` - Enable document generation
- `debug` - Enable debug logging

## Next Steps

1. Review the documentation files
2. Test with your API keys
3. Wait for Priority 1 implementation (document generation)
4. Start using for your research and homelab docs

## Questions?

See the comprehensive documentation in:
- README.md
- IMPLEMENTATION_STATUS.md
- SESSION_SUMMARY.md

## Status

**Foundation**: âœ… Complete  
**Features**: ðŸš§ Coming soon  
**Ready to use**: Yes (with API key)  
**Production ready**: Not yet (features pending)  

---

**Last Updated**: October 17, 2025
